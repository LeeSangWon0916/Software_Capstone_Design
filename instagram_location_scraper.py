import os
import time
import requests
import numpy as np
import cv2
import csv

import instaloader
from instaloader import Post

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

import mediapipe as mp
from roboflow import Roboflow

from climbing_server import compute_spatiogram

# ê²½ë¡œ ì„¤ì •
video_folder = r"C:/Users/ì‚¬ìš©ì/video"
save_folder1 = r"compare_targets"
save_folder2 = r"static"
os.makedirs(video_folder, exist_ok=True)
os.makedirs(save_folder1, exist_ok=True)
os.makedirs(save_folder2, exist_ok=True)

csv_path = "video_info.csv"

# Roboflow ëª¨ë¸ ì´ˆê¸°í™”
rf = Roboflow(api_key="EPZkkKsr1QzoKo0Znukk")
project = rf.workspace("spraywall-id").project("climbing-rv6vd")
model = project.version("2").model

# Mediapipe ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=False, model_complexity=2)
KEYPOINTS = [
    mp_pose.PoseLandmark.LEFT_WRIST,
    mp_pose.PoseLandmark.RIGHT_WRIST,
    #mp_pose.PoseLandmark.LEFT_ANKLE,
    #mp_pose.PoseLandmark.RIGHT_ANKLE
]

# ì˜ìƒ ì •ë³´ ì €ì¥ í•¨ìˆ˜
def save_video_info(image_name, post_url, video_index=None):
    if not os.path.exists("video_info.csv"):
        with open("video_info.csv", mode='w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['image_name', 'instagram_post_url'])

    with open("video_info.csv", mode='a', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        if video_index is not None:
            post_url = f"{post_url}?img_index={video_index}"
        writer.writerow([image_name, post_url])

# ì˜ìƒ ë¶„ì„ í•¨ìˆ˜
def process_video(video_path, save_name, post_url, video_index=None, num_frames=5):

    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    sampled_indices = np.linspace(0, total_frames - 1, num=num_frames, dtype=int)

    ret, frame = cap.read()
    if not ret:
        print(f"âŒ ì²« í”„ë ˆì„ ì½ê¸° ì‹¤íŒ¨: {video_path}")
        return

    frame_height, frame_width, _ = frame.shape
    white_background = np.ones((frame_height, frame_width, 3), dtype=np.uint8) * 255
    white_backgrounds = np.ones((frame_height, frame_width, 3), dtype=np.uint8) * 255
    white_backgroundss = np.ones((frame_height, frame_width, 3), dtype=np.uint8) * 255
    final_backgrounds = np.ones((frame_height, frame_width, 3), dtype=np.uint8) * 255


    for frame_index in sampled_indices:

        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        ret, frame = cap.read()
        if not ret:
            continue

        temp_path = f"temp_frame.jpg"

        cv2.imwrite(temp_path, frame)
        prediction = model.predict(temp_path, confidence=50)
        hold_boxes = prediction.json()['predictions']

        for obj in hold_boxes:
            x, y, w, h = obj["x"], obj["y"], obj["width"], obj["height"]
            x1, y1 = int(x - w / 2), int(y - h / 2)
            x2, y2 = int(x + w / 2), int(y + h / 2)
            hold_crop = frame[y1:y2, x1:x2]

            if hold_crop.size > 0:
                try:
                    white_background[y1:y2, x1:x2] = np.where(
                        hold_crop < 250, hold_crop, white_background[y1:y2, x1:x2]
                    )
                except:
                    continue

    final_path = f"entire_holdmap_{video_index}.jpg"
    cv2.imwrite(final_path, white_background)
    final_prediction = model.predict(final_path, confidence=60)
    final_hold_boxes = final_prediction.json()['predictions']

    hold_rects = []
    for obj in final_hold_boxes:
        x, y, w, h = obj["x"], obj["y"], obj["width"], obj["height"]
        scale = 0.7
        w *= scale
        h *= scale
        x1, y1 = int(x - w / 2), int(y - h / 2)
        x2, y2 = int(x + w / 2), int(y + h / 2)
        # ğŸ”´ ë¹¨ê°„ í…Œë‘ë¦¬ ê·¸ë¦¬ê¸° (ì–‡ê²Œ)
        #cv2.rectangle(white_background, (x1, y1), (x2, y2), (0, 0, 255), 1)
        hold_rects.append(((x1, y1, x2, y2), obj["class"]))

    hold_overlap_counts = {idx: 0 for idx in range(len(hold_rects))}
    hold_overlap_counts_ankle = {idx: 0 for idx in range(len(hold_rects))}
    frame_index = 0
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)


    hold_rects_for_pose = []
    for obj in final_hold_boxes:
        x, y, w, h = obj["x"], obj["y"], obj["width"], obj["height"]
        scale = 1
        w *= scale
        h *= scale
        x1, y1 = int(x - w / 2), int(y - h / 2)
        x2, y2 = int(x + w / 2), int(y + h / 2)
        # ğŸ”´ ë¹¨ê°„ í…Œë‘ë¦¬ ê·¸ë¦¬ê¸° (ì–‡ê²Œ)
        #cv2.rectangle(white_background, (x1, y1), (x2, y2), (0, 0, 255), 1)
        hold_rects_for_pose.append(((x1, y1, x2, y2), obj["class"]))





    while True:
        ret, frame = cap.read()
        if not ret:
            break
        if frame_index % int(fps / 3) == 0:
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            result = pose.process(frame_rgb)
            if result.pose_landmarks:
                for kp in KEYPOINTS:
                    lm = result.pose_landmarks.landmark[kp]
                    x = int(lm.x * frame_width)
                    y = int(lm.y * frame_height)

                    # ğŸ”´ ì†ë°œ ìœ„ì¹˜ì— ë¹¨ê°„ ì  í‘œì‹œ
                    #cv2.circle(white_background, (x, y), 3, (0, 0, 255), -1)

                    for idx, (rect, _) in enumerate(hold_rects_for_pose):
                        x1, y1, x2, y2 = rect
                        if x1 <= x <= x2 and y1 <= y <= y2:
                            hold_overlap_counts[idx] += 1

                
                for kp in [mp_pose.PoseLandmark.LEFT_ANKLE, mp_pose.PoseLandmark.RIGHT_ANKLE]:
                    lm = result.pose_landmarks.landmark[kp]
                    x = int(lm.x * frame_width)
                    y = int(lm.y * frame_height)

                    #cv2.circle(white_background, (x, y), 3, (0, 255, 0), -1)

                    for idx, (rect, _) in enumerate(hold_rects_for_pose):
                        x1, y1, x2, y2 = rect
                        if x1 <= x <= x2 and y1 <= y <= y2:
                            hold_overlap_counts_ankle[idx] += 1



        frame_index += 1

    cv2.imwrite(f"pose_check_{save_name}.jpg", white_background)

    used_hold_indices = {idx for idx, count in hold_overlap_counts.items() if count >= 10}
    for idx in used_hold_indices:
        (x1, y1, x2, y2), _ = hold_rects[idx]
        width = x2 - x1
        height = y2 - y1
        pad_x = 0 # int(width * 0.1)
        pad_y = 0 # int(height * 0.1)
        x1 = max(x1 + pad_x, 0)
        y1 = max(y1 + pad_y, 0)
        x2 = min(x2 - pad_x, frame_width)
        y2 = min(y2 - pad_y, frame_height)
        cropped_hold = white_background[y1:y2, x1:x2]
        white_backgrounds[y1:y2, x1:x2] = cropped_hold

    print(len(used_hold_indices))

    cap.release()

    cv2.imwrite(f"five_{save_name}.jpg", white_backgrounds)

    img = cv2.imread(f"five_{save_name}.jpg")
    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv_img)

    bins_h, bins_s, bins_v= 8, 4, 2
    h_bin = (h.astype(int) * bins_h // 180)
    s_bin = (s.astype(int) * bins_s // 256)
    v_bin = (v.astype(int) * bins_v // 256)

    sp1, _, _ = compute_spatiogram(img, bins_h, bins_s, bins_v)

    #dominant_bin = max(sp1.items(), key=lambda item: item[1]['count'])[0]

    #used_hold_indices = {idx for idx, count in hold_overlap_counts.items() if count >= 3}
    for idx in used_hold_indices:
        (x1, y1, x2, y2), _ = hold_rects[idx]
        width = x2 - x1
        height = y2 - y1
        pad_x = 0 # int(width * 0.1)
        pad_y = 0 # int(height * 0.1)
        x1 = max(x1 + pad_x, 0)
        y1 = max(y1 + pad_y, 0)
        x2 = min(x2 - pad_x, frame_width)
        y2 = min(y2 - pad_y, frame_height)
        cropped_hold = white_background[y1:y2, x1:x2]
        white_backgroundss[y1:y2, x1:x2] = cropped_hold
        cv2.rectangle(white_backgroundss, (x1, y1), (x2, y2), (0, 0, 255), 1)
    
    print(len(used_hold_indices))
    
    cv2.imwrite(f"three_count_{save_name}.jpg", white_backgroundss)

    img_ = cv2.imread(f"three_count_{save_name}.jpg")
    hsv = cv2.cvtColor(img_, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)

    print("hsv : ", h, s, v)

    h_bin = (h.astype(int) * bins_h // 180)
    s_bin = (s.astype(int) * bins_s // 256)
    v_bin = (v.astype(int) * bins_v // 256)

    print("hsv bin : " , h_bin, s_bin, v_bin)

    # dominant bin ì„¸ ê°œ êµ¬í•˜ê¸°
    top_3_bins = sorted(sp1.items(), key=lambda item: item[1]['count'], reverse=True)[:5]
    top_3_counts = [(k, v['count']) for k, v in top_3_bins]
    print(top_3_counts)
    top_3_bin_keys = [bin_key for bin_key, _ in top_3_bins]


    # ê° binì´ ì–¼ë§ˆë‚˜ ë§ì€ í™€ë“œì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê³„ì‚°
    bin_to_hold_count = {bin_key: 0 for bin_key in top_3_bin_keys}

    for bin_key in top_3_bin_keys:
        h_val, s_val, v_val = bin_key
        bin_mask = (h_bin == h_val) & (s_bin == s_val) & (v_bin == v_val)

        # ë§ˆìŠ¤í¬ë¥¼ 0~255 ë²”ìœ„ì˜ uint8 ì´ë¯¸ì§€ë¡œ ë³€í™˜
        mask_img = (bin_mask.astype(np.uint8)) * 255


        # ì €ì¥
        filename = f"bin_mask_{save_name}_{h_val}_{s_val}_{v_val}.png"
        cv2.imwrite(filename, mask_img)

        print(f"{filename} í¬í•¨ í”½ì…€ ìˆ˜:", np.sum(bin_mask))

        if np.sum(bin_mask) > 10000:
            continue

        for idx in used_hold_indices:
            (x1, y1, x2, y2), _ = hold_rects[idx]
            bin_crop = bin_mask[y1:y2, x1:x2]
            if np.count_nonzero(bin_crop) >= 10:
                bin_to_hold_count[bin_key] += 1
    print(bin_to_hold_count)

    # ğŸ’¡ ìµœëŒ€ê°’ í›„ë³´ë“¤ ì°¾ê¸°
    max_count = max(bin_to_hold_count.values())
    candidates = [bin_key for bin_key, count in bin_to_hold_count.items() if count == max_count]

    # ğŸ¯ í›„ë³´ê°€ ì—¬ëŸ¬ ê°œë©´ hê°’ì´ ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” ìª½ ì„ íƒ
    if len(candidates) == 1:
        dominant_bin = candidates[0]
    else:
        # hê°’ ë“±ì¥ íšŸìˆ˜ ì„¸ê¸°
        h_count = {}
        for h_val, _, _ in candidates:
            h_count[h_val] = h_count.get(h_val, 0) + 1
        max_h = max(h_count.items(), key=lambda item: item[1])[0]

        # hê°’ì´ ê°™ì€ í›„ë³´ ì¤‘ ê°€ì¥ ë¨¼ì € ë‚˜ì˜¤ëŠ” ê±¸ ì„ íƒ
        for bin_key in candidates:
            if bin_key[0] == max_h:
                dominant_bin = bin_key
                break

    print("ğŸ¯ ìµœì¢… dominant_bin:", dominant_bin)


    # dominant bin mask ìƒì„±
    '''dominant_bin_mask = (
        (h_bin == dominant_bin[0]) &
        (s_bin == dominant_bin[1]) &
        (v_bin == dominant_bin[2])
)'''







    #dominant_bin_mask = (h_bin == dominant_bin[0]) & (s_bin == dominant_bin[1]) & (v_bin == dominant_bin[2])

    # ğŸ” dominant binê³¼ ê²¹ì¹˜ëŠ” í”½ì…€ì´ 5ê°œ ì´ìƒì¸ ê²½ìš°ë§Œ ë‚¨ê¸°ê¸°
    used_hold_indices = {
    idx for idx, count in hold_overlap_counts.items() if count >= 1
    } | {
    idx for idx, count in hold_overlap_counts_ankle.items() if count >= 1
    }

    white_background_test = np.ones((frame_height, frame_width, 3), dtype=np.uint8) * 255

    for idx in used_hold_indices:
        (x1, y1, x2, y2), _ = hold_rects[idx]
        width = x2 - x1
        height = y2 - y1
        pad_x = 0 # int(width * 0.1)
        pad_y = 0 # int(height * 0.1)
        x1 = max(x1 + pad_x, 0)
        y1 = max(y1 + pad_y, 0)
        x2 = min(x2 - pad_x, frame_width)
        y2 = min(y2 - pad_y, frame_height)
        cropped_hold = white_background[y1:y2, x1:x2]
        white_background_test[y1:y2, x1:x2] = cropped_hold

    cv2.imwrite(f"test_ankle_{save_name}.jpg", white_background_test)

    img_ = cv2.imread(f"test_ankle_{save_name}.jpg")
    hsv = cv2.cvtColor(img_, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)

    h_bin = (h.astype(int) * bins_h // 180)
    s_bin = (s.astype(int) * bins_s // 256)
    v_bin = (v.astype(int) * bins_v // 256)

     # dominant bin mask ìƒì„±
    dominant_bin_mask = (
        (h_bin == dominant_bin[0]) &
        (s_bin == dominant_bin[1]) &
        (v_bin == dominant_bin[2])
    )   


    print(len(used_hold_indices))

    filtered_indices = set()
    for idx in used_hold_indices:
        (x1, y1, x2, y2), _ = hold_rects[idx]
        bin_match_crop = dominant_bin_mask[y1:y2, x1:x2]
        match_count = np.count_nonzero(bin_match_crop)
        print("match : ", match_count)
        if match_count >= 30:
            filtered_indices.add(idx)
    print(len(filtered_indices))

    # ğŸ”² í•´ë‹¹ í™€ë“œë§Œ ìµœì¢… ì´ë¯¸ì§€ì— ë°˜ì˜
    for idx in filtered_indices:
        (x1, y1, x2, y2), _ = hold_rects[idx]
        width = x2 - x1
        height = y2 - y1
        pad_x = 0 # int(width * 0.1)
        pad_y = 0 # int(height * 0.1)
        x1 = max(x1 + pad_x, 0)
        y1 = max(y1 + pad_y, 0)
        x2 = min(x2 - pad_x, frame_width)
        y2 = min(y2 - pad_y, frame_height)
        cropped_hold = white_background[y1:y2, x1:x2]
        final_backgrounds[y1:y2, x1:x2] = cropped_hold

    folders = ["static", "compare_targets"]

    for folder in folders:
        save_path = os.path.join(folder, f"used_holds_{save_name}.jpg")
        cv2.imwrite(save_path, final_backgrounds)

    # ì˜ìƒ ì •ë³´ ì €ì¥
    save_video_info(f"used_holds_{save_name}.jpg", post_url, video_index)

    # ì˜ìƒ ì‚­ì œ
    if os.path.exists(video_path):
        os.remove(video_path)
        print(f"ğŸ—‘ï¸ ë¶„ì„ í›„ ì˜ìƒ ì‚­ì œ: {video_path}")

# ìŠ¤í¬ë˜í•‘ í•¨ìˆ˜
def scrape_location_posts(location_url, num_scrolls=0):
    options = webdriver.ChromeOptions()
    options.add_argument("user-data-dir=C:/Users/ì‚¬ìš©ì/AppData/Local/Google/Chrome/NewProfile2")
    options.add_argument("profile-directory=Default")
    options.add_argument("--start-maximized")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.get(location_url)
    time.sleep(3)
    for _ in range(num_scrolls):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'a')))
        time.sleep(10)

    post_links = []
    elems = driver.find_elements(By.XPATH, "//*[contains(@class, 'x1i10hfl')]")
    for e in elems:
        href = e.get_attribute('href')
        if href and "/p/" in href:
            post_links.append(href)
    driver.quit()

    results = []
    for link in post_links:
        results.append([link, ""])
    return results

# ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„ í†µí•© í•¨ìˆ˜
def download_and_process_videos(results):
    L = instaloader.Instaloader(save_metadata=False, download_comments=False)
    #L.login('onam1st_climb', 'awardcycle1519!')

    for post_url, _ in results:
        if "/p/" not in post_url:
            continue
        shortcode = post_url.split("/p/")[1].split("/")[0]
        save_name = shortcode

        already_analyzed = os.path.exists(os.path.join(save_folder1, f"used_holds_{save_name}.jpg"))
        if already_analyzed:
            print(f"â­ï¸ ì´ë¯¸ ë¶„ì„ë¨, ìŠ¤í‚µ: {save_name}")
            continue

        try:
            post = Post.from_shortcode(L.context, shortcode)
            if post.is_video:
                video_url = post.video_url
                video_path = os.path.join(video_folder, f"{save_name}.mp4")
                if not os.path.exists(video_path):
                    video_bytes = requests.get(video_url).content
                    with open(video_path, "wb") as f:
                        f.write(video_bytes)
                    print(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {video_path}")
                # process_video(video_path, save_name, post_url)
            elif post.typename == "GraphSidecar":
                for idx, sidecar_node in enumerate(post.get_sidecar_nodes()):
                    if sidecar_node.is_video:
                        video_url = sidecar_node.video_url
                        short_id = f"{save_name}_video_{idx+1}"
                        video_path = os.path.join(video_folder, f"{short_id}.mp4")
                        if not os.path.exists(video_path):
                            video_bytes = requests.get(video_url).content
                            with open(video_path, "wb") as f:
                                f.write(video_bytes)
                            print(f"ğŸ“¥ ë©€í‹°í¬ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ: {video_path}")
                        process_video(video_path, short_id, post_url, video_index=idx + 1)
        except Exception as e:
            print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {post_url} - {e}")

# ì‹¤í–‰
if __name__ == "__main__":
    location_url = "https://www.instagram.com/explore/locations/132859156463624/-theclimb-sadang/recent/"
    post_list = scrape_location_posts(location_url, num_scrolls=0)
    '''post_list = [
                #['https://www.instagram.com/p/DJ1qJ86SOvb/?img_index=11&igsh=dDhhbGRvODlobTV1', ''],
                 #['https://www.instagram.com/p/DJ1dYHOP6cM/?img_index=9&igsh=Mms5M3hvYXhqOXB2', ''],
                 ['https://www.instagram.com/p/DJ0NeFuSYi_/?img_index=13&igsh=YWV6bWNkYWtqajA3', ''],
                 #['https://www.instagram.com/p/DJyz3lJyQNa/?img_index=4&igsh=MTB4dDlta2F5bXRjMg==', '']
                 ]'''

    download_and_process_videos(post_list)